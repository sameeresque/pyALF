{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99723d35-d572-4692-947b-068fe7382aa9",
   "metadata": {},
   "source": [
    "## Load the imports\n",
    "## Among the imported packages, PyNorm is a publicly available Python library designed for measuring absorption lines in astronomical spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4b2dc-491b-4e09-b02f-93301cc4c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is to know when this notebook has been run last time and with which python version.\n",
    "import time, sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import dropbox\n",
    "from dropbox import files\n",
    "from dropbox.exceptions import AuthError\n",
    "import asdf\n",
    "import numpy as np\n",
    "import pickle\n",
    "os.sys.path.append('/afs/crc.nd.edu/user/s/sameer/pyNorm/pyNorm/')\n",
    "import spectres\n",
    "from ios import read_inorm\n",
    "from aod import pyn_batch\n",
    "from ios import myfuncpyNorm\n",
    "from scipy.interpolate import interp1d\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from itertools import combinations\n",
    "from scipy.signal import argrelextrema, argrelmax\n",
    "os.sys.path.append('/afs/crc.nd.edu/user/s/sameer/Research/LineFinder/Spectra/')\n",
    "os.chdir('/afs/crc.nd.edu/user/s/sameer/Research/LineFinder/Spectra/')\n",
    "from functions_pyALF import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354de82d-bb46-4381-9a6d-f247e9472282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdictsep(wave,flux,error,species,z):\n",
    "    \"\"\"\n",
    "    \n",
    "    This function is meant to create a dictionary consisting of keys that can be ingested by PyNorm. \n",
    "    Args:\n",
    "        wave (array of floats): The observed wavelength array\n",
    "        flux (array of floats): The normalized flux array\n",
    "        error (array of floats): The array of errors associated with the normalized flux\n",
    "        species (dict) : The dictionary comprising of information on atomic line data\n",
    "        z (float): The redshift of the absorption system whose measurements are of interest.\n",
    "    Returns:\n",
    "        dict: A dictionary that can be ingested by PyNorm for performing line measurements.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    dictionary = {}\n",
    "    obs_wave = wave\n",
    "    flux = flux\n",
    "    error = error\n",
    "    \n",
    "    for specie in species:\n",
    "        for transition in species[specie]:\n",
    "\n",
    "            vel = getVel(obs_wave,species[specie][transition][0],z)\n",
    "            #print (vel)\n",
    "            \n",
    "            vel_sel = np.where((vel<=4000) & (vel>=-4000))\n",
    "\n",
    "            dictionary['{}_{}'.format(specie,transition)] = {'z':z,'vel':vel[vel_sel],'flux':flux[vel_sel],'eflux':error[vel_sel],\n",
    "            'wavc':species[specie][transition][0],\n",
    "            'fval':species[specie][transition][1],\n",
    "            'contin':np.ones(len(vel[vel_sel])),\n",
    "            'contin_err':np.zeros(len(vel[vel_sel]))}\n",
    "            \n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a7b60-df75-4a19-af84-e037ddf304ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebin_spectra(vel1, flux1, vel2, flux2, new_vel):\n",
    "    \"\"\"\n",
    "    This function is meant to rebin a spectrum onto a common velocity axis.\n",
    "\n",
    "    Args:\n",
    "        vel1: velocity array of the first spectrum\n",
    "        flux1: flux array of the first spectrum\n",
    "        vel2: velocity array of the second spectrum\n",
    "        flux2: flux array of the second spectrum        \n",
    "\n",
    "    Returns:\n",
    "        arrays: flux arrays of the first and second spectra.\n",
    "    \"\"\"\n",
    "    \n",
    "    interp_flux1 = interp1d(vel1, flux1, kind='linear', bounds_error=False, fill_value=np.nan)\n",
    "    interp_flux2 = interp1d(vel2, flux2, kind='linear', bounds_error=False, fill_value=np.nan)\n",
    "\n",
    "    new_flux1 = interp_flux1(new_vel)\n",
    "    new_flux2 = interp_flux2(new_vel)\n",
    "\n",
    "    return new_flux1, new_flux2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810430b5-b3e2-48ad-ab50-ac18f34e4968",
   "metadata": {},
   "source": [
    "## Read in the atomic data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd999a4-232e-4434-bcc3-cd65b9700d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_library=pd.read_table('atomdata_updated_new.dat', sep='\\s+',header=None,comment = \"#\")\n",
    "transition_library=np.asarray(transition_library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d80550-31cb-41af-8546-a2009a31aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linedetect(filein,plot_ions,transition_library,choose):\n",
    "    \"\"\"\n",
    "    This function creates a dataframe of detected absorption lines in a given spectrum. This is now tailored for HI absorption. \n",
    "    It uses several functions from functions_pyALF.py, such as speciesinterest, blue_red_limits, fluxselector, absorptionlocator, addvel2spec, and getdf.\n",
    "    \"\"\"\n",
    "    \n",
    "    af = asdf.open(filein)\n",
    "    wave = np.asarray(af['wave'].byteswap().newbyteorder())\n",
    "    wave = np.array(wave, dtype=\"<f8\")\n",
    "    flux = np.asarray(af['flux'].byteswap().newbyteorder())\n",
    "    flux = np.array(flux, dtype=\"<f8\")\n",
    "    err = np.asarray(af['err'].byteswap().newbyteorder())\n",
    "    err = np.array(err, dtype=\"<f8\")\n",
    "    d = {'WAVELENGTH':wave,'FLUX':flux,'ERROR':err}\n",
    "    spec=pd.DataFrame(data=d)\n",
    "    species=speciesinterest(plot_ions,transition_library,choose=None)\n",
    "    zem = af['zqso']\n",
    "    blue_limit, max_red = blue_red_limits(zem,spec['WAVELENGTH'],species,flag=1)\n",
    "    selected_spec = fluxselector(spec,blue_limit,max_red)\n",
    "    #selected_spec = spec\n",
    "    selected_spec['Rest-Wavelength']=selected_spec['WAVELENGTH']/(1.0+zem)\n",
    "    pr = absorptionlocator(selected_spec)\n",
    "    selected_spec = addvel2spec(selected_spec,species)\n",
    "    df=getdf(selected_spec,species,zem,pr,{'HI':(-abs(findV(0,zem)),abs(findV(0,zem)))})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91575970-9e6e-429a-b467-4da3cda01f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathtodir = '/afs/crc.nd.edu/user/s/sameer/Research/LineFinder/Spectra/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02656c68-ff19-469e-8940-154bda114162",
   "metadata": {},
   "source": [
    "## Detect lines in an inputted spectrum. Here the example of J121930+494052. The input file is in .asdf format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7559a56b-5382-4bad-bd4e-8a817d869a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qso = 'J121930+494052'\n",
    "filein = '{0}{1}/{1}.asdf'.format(pathtodir,qso)\n",
    "plot_ions=['HI']\n",
    "af = asdf.open(filein)\n",
    "wave = np.asarray(af['wave'])\n",
    "wave = np.array(wave, dtype=\"<f8\")\n",
    "flux = np.asarray(af['flux'])\n",
    "flux = np.array(flux, dtype=\"<f8\")\n",
    "err = np.asarray(af['err'])\n",
    "err = np.array(err, dtype=\"<f8\")\n",
    "d = {'WAVELENGTH':wave,'FLUX':flux,'ERROR':err}\n",
    "spec=pd.DataFrame(data=d)\n",
    "species=speciesinterest(plot_ions,transition_library,choose=None)\n",
    "zem = af['zqso']\n",
    "blue_limit, max_red = blue_red_limits(zem,spec['WAVELENGTH'],species,flag=1)\n",
    "selected_spec = fluxselector(spec,blue_limit,max_red)\n",
    "\n",
    "selected_spec['Rest-Wavelength']=selected_spec['WAVELENGTH']/(1.0+zem)\n",
    "pr = absorptionlocator(selected_spec)\n",
    "selected_spec = addvel2spec(selected_spec,species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75be995-c42a-4fab-8447-1400d1fbee0f",
   "metadata": {},
   "source": [
    "## The following cell determines to which HI transition an absorption line is potentially associated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081841a-ecc2-49b3-81b8-1b28b01d6e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def remove_empty_filter_dictionary(my_dict):\n",
    "    \"\"\"\n",
    "    This function removes keys with empty values\n",
    "    \"\"\"\n",
    "    filtered_dict = {k: v for k, v in my_dict.items() if v}\n",
    "    return filtered_dict\n",
    "\n",
    "def filter_and_transform_dictionary(dictionary, threshold):\n",
    "    \"\"\"\n",
    "    This function is used to remove any absorption systems that are beyond the emission redshift of the quasar.\n",
    "    \"\"\"\n",
    "    filtered_dict = {key: [min(values), max(values)] for key, values in dictionary.items() if any(val <= threshold for val in values)}\n",
    "    return filtered_dict\n",
    "\n",
    "pr_dict=OrderedDict()\n",
    "for num,pr_i in enumerate(pr):\n",
    "    \n",
    "    z_window = OrderedDict()\n",
    "    wave_window = selected_spec[pr_i[0]:pr_i[1]]['WAVELENGTH']\n",
    "    for transition in species['HI']:\n",
    "        z_window[transition] = (wave_window/species['HI'][transition][0]) - 1.0\n",
    "    filtered_dictionary = filter_and_transform_dictionary(z_window, zem)\n",
    "    pr_dict[num] = filtered_dictionary   \n",
    "\n",
    "\n",
    "pr_dict_n = remove_empty_filter_dictionary(pr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a3243-4185-48bc-a23f-4e751351f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_dict_n[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972698d-f5c1-47cd-8527-faf9a5c7b15d",
   "metadata": {},
   "source": [
    "## The following cell determines the absorption in various HI transitions with overlapping redshifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7687dc4-3dac-4ddf-ad57-c1c25fa77341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlapping_bounds(outer_dict):\n",
    "    \"\"\"\n",
    "    This function finds absorption components that overlap in redshift. \n",
    "    These overlapping components could be absorption arising from different HI transitions of the same absorption system.\n",
    "    However, these components are vetted further below to remove false positives.\n",
    "    \"\"\"\n",
    "    \n",
    "    overlapping_outer_inner_keys = []\n",
    "\n",
    "    outer_keys = list(outer_dict.keys())\n",
    "\n",
    "    for i in range(len(outer_keys)):\n",
    "        for j in range(i + 1, len(outer_keys)):\n",
    "            outer_key1, outer_key2 = outer_keys[i], outer_keys[j]\n",
    "            inner_dict1, inner_dict2 = outer_dict[outer_key1], outer_dict[outer_key2]\n",
    "\n",
    "            for key1, bounds1 in inner_dict1.items():\n",
    "                for key2, bounds2 in inner_dict2.items():\n",
    "                    if (bounds1[0] <= bounds2[1] and bounds1[1] >= bounds2[0]) or \\\n",
    "                       (bounds2[0] <= bounds1[1] and bounds2[1] >= bounds1[0]):\n",
    "                        overlapping_outer_inner_keys.append(((outer_key1, key1), (outer_key2, key2)))\n",
    "\n",
    "    combined_tuples = []\n",
    "    for i, tuple1 in enumerate(overlapping_outer_inner_keys):\n",
    "        combined_tuple = list(tuple1)\n",
    "        for j, tuple2 in enumerate(overlapping_outer_inner_keys[i + 1:]):\n",
    "            if set(tuple1).intersection(set(tuple2)):\n",
    "                combined_tuple.extend(x for x in tuple2 if x not in tuple1)\n",
    "        combined_tuples.append(tuple(combined_tuple))\n",
    "\n",
    "    return combined_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a89bdc-486c-4d3b-85e7-6807ecc677e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1 = find_overlapping_bounds(pr_dict_n)\n",
    "#pickle.dump(t1,open('overlappingbounds_J121930+494052.pkl','wb'),protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf1923-a5eb-4664-927f-bc8e54f46791",
   "metadata": {},
   "source": [
    "## The above step is a time consuming step, and it needs to be optimized. For now, I have saved the output of the step to a pickled file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a08c7d-c739-4add-884e-6da91302d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.read_pickle('overlappingbounds_J121930+494052.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9e9b9-7707-45c1-90de-1b3bae31e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tuples(tuple_list):\n",
    "    \"\"\"\n",
    "    Split a list of tuples into groups based on increasing first elements.\n",
    "\n",
    "    This function takes a list of tuples and splits it into groups where the first\n",
    "    element of each tuple is in ascending order within each group. A new group is\n",
    "    started whenever the first element of a tuple is less than or equal to the\n",
    "    first element of the previous tuple.\n",
    "\n",
    "    Parameters:\n",
    "    tuple_list (list): A list of tuples, where each tuple has at least one element.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of tuples, where each tuple contains a group of original tuples\n",
    "          with increasing first elements.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    result = []\n",
    "    current_group = []\n",
    "\n",
    "    for tpl in tuple_list:\n",
    "        if not current_group or tpl[0] > current_group[-1][0]:\n",
    "            current_group.append(tpl)\n",
    "        else:\n",
    "            result.append(tuple(current_group))\n",
    "            current_group = [tpl]\n",
    "\n",
    "    if current_group:\n",
    "        result.append(tuple(current_group))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "new_list = []\n",
    "for num_t1,blk in enumerate(t1):\n",
    "    result_list = split_tuples(blk)\n",
    "    new_list.append(result_list)\n",
    "import itertools\n",
    "merged = list(itertools.chain(*new_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52670c8f-24ed-4656-97e0-e6d15de66bf0",
   "metadata": {},
   "source": [
    "## The next step aims to reduce false positives by leveraging our spectral coverage. Genuine absorption should include the detection of the Hydrogen I (HI) Lyman-alpha line at 1215 Angstroms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964cbf8-c9fc-4878-b2e9-ca6e388591a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list = [tpl for tpl in merged if any(subtpl[1] == '1215' for subtpl in tpl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e968d1d-77a7-43c9-b4d8-14f96fbaa855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getinfozblock(wave,flux,err,block):\n",
    "    \"\"\"\n",
    "    Analyze spectral data for a given block of transitions.\n",
    "\n",
    "    This function processes spectral data for a set of transitions, calculates\n",
    "    redshift ranges, and extracts properties for each transition.\n",
    "\n",
    "    Parameters:\n",
    "    wave (array-like): Wavelength data of the spectrum.\n",
    "    flux (array-like): Flux data of the spectrum.\n",
    "    err (array-like): Error data of the spectrum.\n",
    "    block (list): A list of tuples, each containing element and transition information.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing properties for each unique transition in the block.\n",
    "          Each key is a transition identifier, and the value is a dictionary of\n",
    "          spectral properties for that transition.\n",
    "\n",
    "    Notes:\n",
    "    - The function uses several external dictionaries and functions (pr_dict_n,\n",
    "      transition_library, myfuncpyNorm, etc.) which should be defined elsewhere\n",
    "      in the code.\n",
    "    - It calculates a common center of redshifts for the given transitions.\n",
    "    - The function focuses on Hydrogen I (HI) transitions.\n",
    "    - Properties are calculated within velocity ranges determined by the redshift\n",
    "      limits of each transition.\n",
    "    \"\"\"\n",
    "    \n",
    "    z_element = []\n",
    "    choose_transitions = []\n",
    "    for element in block:\n",
    "        z_element.append(pr_dict_n[element[0]][element[1]])\n",
    "        choose_transitions.append(element[1])\n",
    "\n",
    "    \n",
    "    min_first = min(z_element, key=lambda x: x[0])[0]\n",
    "    max_second = max(z_element, key=lambda x: x[1])[1]\n",
    "    center = 0.5*(min_first+max_second)\n",
    "\n",
    "\n",
    "    use_species = myfuncpyNorm.speciesinterest(['HI'],transition_library,choose={'HI':list(set(choose_transitions))})\n",
    "    makeinpdict = getdictsep(wave,flux,err,use_species,center)\n",
    "\n",
    "\n",
    "    z_l,z_h = [],[]\n",
    "    for num, element in enumerate(block):    \n",
    "        z_l.append((element[1],pr_dict_n[element[0]][element[1]][0])) \n",
    "        z_h.append((element[1],pr_dict_n[element[0]][element[1]][1]))\n",
    "        \n",
    "\n",
    "    unique_values_min = {}\n",
    "\n",
    "    #print (z_l)\n",
    "    for key, value in z_l:\n",
    "        if key not in unique_values_min:\n",
    "            unique_values_min[key] = value\n",
    "        else:\n",
    "            unique_values_min[key] = min(unique_values_min[key], value)\n",
    "    \n",
    "    # Creating a list of unique tuples\n",
    "    unique_tuples_min = [(key, value) for key, value in unique_values_min.items()]\n",
    "    #print (unique_tuples_min)\n",
    "\n",
    "    unique_values_max = {}\n",
    "    \n",
    "    for key, value in z_h:\n",
    "        if key not in unique_values_max:\n",
    "            unique_values_max[key] = value\n",
    "        else:\n",
    "            unique_values_max[key] = max(unique_values_max[key], value)\n",
    "    \n",
    "    # Creating a list of unique tuples\n",
    "    unique_tuples_max = [(key, value) for key, value in unique_values_max.items()]\n",
    "\n",
    "\n",
    "    properties = {}\n",
    "\n",
    "    for num,transition in enumerate(unique_tuples_min):\n",
    "        v1,v2 = -findV(unique_tuples_min[num][1],center), findV(center,unique_tuples_max[num][1])\n",
    "\n",
    "        vmin,vmax = min(makeinpdict['HI_{}'.format(transition[0])]['vel']),max(makeinpdict['HI_{}'.format(transition[0])]['vel'])\n",
    "\n",
    "        \n",
    "        v1 = v1 if vmin<v1 else vmin\n",
    "        v2 = v2 if vmax>v2 else vmax\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        properties[transition[0]] = myfuncpyNorm.getproperty(makeinpdict['HI_{}'.format(transition[0])],[v1,v2])\n",
    "    \n",
    "    return properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ae833-1582-4693-a034-daa0e6f541ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_transitions_tuples(inp):\n",
    "    \"\"\"\n",
    "    Merge and group spectral transitions based on velocity proximity.\n",
    "\n",
    "    This function analyzes multiple spectral transitions, identifies peaks,\n",
    "    and groups transitions that have matching peaks within a 10 km/s velocity range.\n",
    "\n",
    "    Parameters:\n",
    "    inp (dict): A dictionary where keys are transition identifiers and values are\n",
    "                dictionaries containing 'vel' (velocity), 'Nav' (flux), and 'z' (redshift) data.\n",
    "\n",
    "    Returns:\n",
    "    list of tuples: Each tuple contains:\n",
    "                    - A velocity key (float, rounded to 2 decimal places)\n",
    "                    - A tuple of transition information, where each item is a tuple of:\n",
    "                      (velocity, transition identifier, calculated absorption redshift)\n",
    "\n",
    "    Notes:\n",
    "    - The function uses numpy for quantile calculations and scipy's find_peaks for peak detection.\n",
    "    - Peaks are identified using a width of 5, and a height/prominence threshold of the 25th percentile\n",
    "      of positive flux values.\n",
    "    - Transitions are considered matching if their peak velocities are within 10 km/s of each other.\n",
    "    - The returned list is sorted by the velocity key.\n",
    "    - The function assumes the existence of a 'findZAbs' function to calculate absorption redshift.\n",
    "    \"\"\"\n",
    "    \n",
    "    merged_transitions = {}\n",
    "\n",
    "    transitions_dict = inp\n",
    "    for idx, (transition1, transition2) in enumerate(combinations(transitions_dict.keys(), 2)):\n",
    "        velocity1 = transitions_dict[transition1]['vel']\n",
    "        flux1 = transitions_dict[transition1]['Nav']\n",
    "        velocity2 = transitions_dict[transition2]['vel']\n",
    "        flux2 = transitions_dict[transition2]['Nav']\n",
    "    \n",
    "        z1 = transitions_dict[transition1]['z']\n",
    "        z2 = transitions_dict[transition2]['z']\n",
    "        \n",
    "        use_height_1 = np.quantile(flux1[flux1>0],0.25)\n",
    "        use_height_2 = np.quantile(flux2[flux2>0],0.25)\n",
    "    \n",
    "        flux1_ = flux1[flux1>use_height_1]\n",
    "        flux2_ = flux2[flux2>use_height_2]\n",
    "        \n",
    "        \n",
    "        # Find peaks in flux arrays\n",
    "        peaks1, _ = find_peaks(flux1, width = 5, height = use_height_1,prominence = use_height_1)\n",
    "        peaks2, _ = find_peaks(flux2, width = 5, height = use_height_2,prominence = use_height_2)\n",
    "        \n",
    "\n",
    "        \n",
    "        # Check for matching peaks within 10 km/s\n",
    "        for peak1 in peaks1:\n",
    "            for peak2 in peaks2:\n",
    "                if abs(velocity1[peak1] - velocity2[peak2]) <= 10:\n",
    "                    # Group matching transitions based on velocity proximity\n",
    "                    key = round(velocity1[peak1], 2)  # Using velocity as key (rounded to two decimal places)\n",
    "                    if key not in merged_transitions:\n",
    "                        merged_transitions[key] = set()  # Initialize set if key not present\n",
    "                    merged_transitions[key].add((velocity1[peak1], transition1, findZAbs(-velocity1[peak1],z1)))\n",
    "                    merged_transitions[key].add((velocity2[peak2], transition2, findZAbs(-velocity2[peak2],z2)))\n",
    "    \n",
    "    # Convert sets to tuples\n",
    "    merged_transitions_tuples = [(key, tuple(value)) for key, value in merged_transitions.items()]\n",
    "    merged_transitions_tuples.sort(key = lambda x: x[0])\n",
    "    return merged_transitions_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4ac99-7a5a-4d25-bef5-9f92058ee573",
   "metadata": {},
   "source": [
    "## The following cell determines the redshifts where there are overlapping HI transitions. This step is also a time consuming step. So, the output of this execution is saved as a picked file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d013c5-2593-4809-a608-0393eca1cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_list = []\n",
    "for num,list_ in enumerate(filtered_list):\n",
    "    print (num)\n",
    "    inp = getinfozblock(wave,flux,err,list_)\n",
    "    output_list = get_merged_transitions_tuples(inp)\n",
    "    for item_ in output_list:\n",
    "        for vel in item_[1]:\n",
    "            redshift_list.append(vel[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17bb04-78d7-47f3-9fee-78b43fbab4a8",
   "metadata": {},
   "source": [
    "## Counts the number of occurences of a redshift. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52f694-889b-4265-8791-596e99d687aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "number_counts = Counter(redshift_list)\n",
    "\n",
    "result_list = sorted(number_counts.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a263869-9288-468d-8f72-07d3cb76eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(result_list,open('resultlist_J121930+494052.pkl','wb'),protocol=2)\n",
    "res_list = pd.read_pickle('resultlist_J121930+494052.pkl')\n",
    "\n",
    "sorted_res_list =sorted(res_list, key=lambda element: element[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e770cbb-5c22-49bf-9fe9-fafaed2d9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,FuncFormatter,\n",
    "                               AutoMinorLocator)\n",
    "\n",
    "import spectres\n",
    "\n",
    "#plt.style.use('seaborn-white')\n",
    "plt.rc('font', family='serif')\n",
    "fig = plt.figure(figsize=(7,14))\n",
    "\n",
    "ax = fig.add_subplot(511)\n",
    "ax1 = fig.add_subplot(512,sharex = ax)\n",
    "ax2 = fig.add_subplot(513,sharex = ax)\n",
    "ax3 = fig.add_subplot(514,sharex = ax)\n",
    "ax4 = fig.add_subplot(515,sharex = ax)\n",
    "\n",
    "\n",
    "vel = getVel(wave,species['HI']['1215'][0],2.57761)\n",
    "\n",
    "vel_sel = np.where((vel<=500) & (vel>=-500))\n",
    "ax.errorbar(vel[vel_sel],flux[vel_sel],color='gray', yerr=err[vel_sel],fmt='.',ls='none',label='HI-1215')\n",
    "\n",
    "vel = getVel(wave,species['HI']['1025'][0],2.57761)\n",
    "\n",
    "vel_sel = np.where((vel<=500) & (vel>=-500))\n",
    "ax1.errorbar(vel[vel_sel],flux[vel_sel],color='gray', yerr=err[vel_sel],fmt='.',ls='none',label='HI-1025')\n",
    "\n",
    "vel = getVel(wave,species['HI']['972'][0],2.57761)\n",
    "\n",
    "vel_sel = np.where((vel<=500) & (vel>=-500))\n",
    "ax2.errorbar(vel[vel_sel],flux[vel_sel],color='gray', yerr=err[vel_sel],fmt='.',ls='none',label='HI-972')\n",
    "\n",
    "vel = getVel(wave,species['HI']['937'][0],2.57761)\n",
    "\n",
    "vel_sel = np.where((vel<=500) & (vel>=-500))\n",
    "ax3.errorbar(vel[vel_sel],flux[vel_sel],color='gray', yerr=err[vel_sel],fmt='.',ls='none',label='HI-937')\n",
    "\n",
    "vel = getVel(wave,species['HI']['912'][0],2.57761)\n",
    "\n",
    "vel_sel = np.where((vel<=500) & (vel>=-500))\n",
    "ax4.errorbar(vel[vel_sel],flux[vel_sel],color='gray', yerr=err[vel_sel],fmt='.',ls='none',label='HI-912')\n",
    "\n",
    "for axi in [ax,ax1,ax2,ax3,ax4]:\n",
    "    axi.legend(frameon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3c7d4-1d53-45e3-9d5b-d12a906e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,FuncFormatter,\n",
    "                               AutoMinorLocator)\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rc('font', family='serif')\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "ax.errorbar(properties_lya['vel'],properties_lya['Nav'],color='gray', yerr=properties_lya['Nav_err'],fmt='.',ls='none')\n",
    "ax.errorbar(properties_lyb['vel'],properties_lyb['Nav'],color='orange', yerr=properties_lyb['Nav_err'],fmt='.',ls='none')\n",
    "#ax.errorbar(properties_lyg['vel'],properties_lyg['Nav'],color='blue', yerr=properties_lyg['Nav_err'],fmt='.',ls='none')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ebf5a-32a0-4d92-8a05-c41fe65e2e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each item in filtered list, obtain merged_transitions_tuples. Append the tuples and find the frequently occuring redshifts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0447bef6-ba99-4892-911c-8da2282d882b",
   "metadata": {},
   "source": [
    "## Table 2 from KODIAQ Survey Lehner et al. 2022.\n",
    "\n",
    "## The paper focused on identifying strong HI (neutral hydrogen) absorbers. The proposed algorithm is expected to have broader capabilities. It should be able to detect not only the strong absorbers identified in the paper but also weaker HI absorbers that may not meet the criteria for classification as strong absorbers. This expanded detection range could potentially reveal a more comprehensive set of HI absorbers in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e8695-02e9-4bb4-8716-1d938dbb6ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2kd = pd.read_csv('/afs/crc.nd.edu/user/s/sameer/Research/LineFinder/Table2KODIAQ.txt', sep= '\\s+',skiprows = 42,names= ['Target','zabs','Element','IonizationState','v1','v2',                                                                                                            'Avg.V','Err_Avg.V','logN','E_logN','e_logN','DetectionFlag','ReliabilityFlag','UniqueID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915fc0ce-e01a-4e86-9e8d-2d469c585edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2kd_HI = table2kd[table2kd['Element']=='H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0fecc0-02ce-4eac-89cd-83a6bcab77e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2kd_HI_chosen = table2kd_HI[table2kd_HI['Target']=='J121930+494052']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b284eb-1589-447c-a60e-f559a1986fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2kd_HI_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b17100-6e00-4863-975b-6f7e533bf994",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,FuncFormatter,\n",
    "                               AutoMinorLocator)\n",
    "\n",
    "import spectres\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rc('font', family='serif')\n",
    "fig = plt.figure(figsize=(7,14))\n",
    "\n",
    "ax = fig.add_subplot(511)\n",
    "ax1 = fig.add_subplot(512,sharex = ax)\n",
    "ax2 = fig.add_subplot(513,sharex = ax)\n",
    "ax3 = fig.add_subplot(514,sharex = ax)\n",
    "ax4 = fig.add_subplot(515,sharex = ax)\n",
    "\n",
    "for num,res in enumerate(result_list[0:500]):\n",
    "    plt.cla()\n",
    "    ax.clear()\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "    ax3.clear()\n",
    "    ax4.clear()\n",
    "    vel = getVel(wave,species['HI']['1215'][0],res[0])\n",
    "    \n",
    "    vel_sel = np.where((vel<=500) & (vel>=-500))\n",
    "    ax.errorbar(vel[vel_sel],flux[vel_sel],color='gray', yerr=err[vel_sel],fmt='.',ls='none',label='HI-1215')\n",
    "    \n",
    "    vel = getVel(wave,species['HI']['1025'][0],res[0])\n",
    "    \n",
    "    vel_sel = np.where((vel<=500) & (vel>=-500))\n",
    "    ax1.errorbar(vel[vel_sel],flux[vel_sel],color='gray', yerr=err[vel_sel],fmt='.',ls='none',label='HI-1025')\n",
    "    \n",
    "    vel = getVel(wave,species['HI']['972'][0],res[0])\n",
    "    \n",
    "    vel_sel = np.where((vel<=500) & (vel>=-500))\n",
    "    ax2.errorbar(vel[vel_sel],flux[vel_sel],color='gray', yerr=err[vel_sel],fmt='.',ls='none',label='HI-972')\n",
    "    \n",
    "    vel = getVel(wave,species['HI']['949'][0],res[0])\n",
    "    \n",
    "    vel_sel = np.where((vel<=500) & (vel>=-500))\n",
    "    ax3.errorbar(vel[vel_sel],flux[vel_sel],color='gray', yerr=err[vel_sel],fmt='.',ls='none',label='HI-949')\n",
    "    \n",
    "    vel = getVel(wave,species['HI']['937'][0],res[0])\n",
    "    \n",
    "    vel_sel = np.where((vel<=500) & (vel>=-500))\n",
    "    ax4.errorbar(vel[vel_sel],flux[vel_sel],color='gray', yerr=err[vel_sel],fmt='.',ls='none',label='HI-937')\n",
    "    \n",
    "    for axi in [ax,ax1,ax2,ax3,ax4]:\n",
    "        axi.legend(frameon=True)   \n",
    "    ax.set_title('{}'.format(res[0]))\n",
    "    plt.savefig('{}.png'.format(num), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ccb98-e57f-4e6d-b5ff-b46a518009aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(t1,t2,makeinpdict):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two spectra.\n",
    "\n",
    "    This function processes two spectra, normalizes them, and calculates their cosine similarity.\n",
    "    It handles rebinning of spectra to ensure they are on the same velocity grid before comparison.\n",
    "\n",
    "    Parameters:\n",
    "    t1 (str or int): Identifier for the first spectrum in makeinpdict.\n",
    "    t2 (str or int): Identifier for the second spectrum in makeinpdict.\n",
    "    makeinpdict (dict): A dictionary containing spectral data for different identifiers.\n",
    "\n",
    "    Returns:\n",
    "    float: The cosine similarity between the two spectra, ranging from -1 to 1.\n",
    "           1 indicates perfect similarity, 0 indicates no similarity, and -1 indicates perfect dissimilarity.\n",
    "\n",
    "    Notes:\n",
    "    - The function uses a velocity range of -100 to 100 km/s for the comparison.\n",
    "    - Spectra are rebinned to a common velocity grid if necessary.\n",
    "    - The spectra are normalized before calculating cosine similarity.\n",
    "    - Uses external functions: myfuncpyNorm.getproperty, rebin_spectra, and cosine_similarity.\n",
    "    \"\"\"\n",
    "    \n",
    "    properties1 = myfuncpyNorm.getproperty(makeinpdict[t1],[-100,100])\n",
    "    properties2 = myfuncpyNorm.getproperty(makeinpdict[t2],[-100,100])\n",
    "\n",
    "    vel1 = properties1['vel']\n",
    "    vel_sel1 = np.where((vel1<=100) & (vel1>=-100))\n",
    "    vel1_use = vel1[vel_sel1]\n",
    "    spectrum1 = properties1['Nav'][vel_sel1]\n",
    "    \n",
    "    vel2 = properties2['vel']\n",
    "    vel_sel2 = np.where((vel2<=100) & (vel2>=-100))\n",
    "    vel2_use = vel2[vel_sel2]\n",
    "    spectrum2 = properties2['Nav'][vel_sel2]\n",
    "    \n",
    "    \n",
    "    spectrum1,spectrum2 = rebin_spectra(vel1_use, spectrum1, vel2_use, spectrum2, np.arange(min(vel1_use[0],vel2_use[0]),max(vel1_use[-1],vel2_use[-1])+vel1[1]-vel1[0],vel1[1]-vel1[0]))\n",
    "    \n",
    "    spectrum1_norm = spectrum1 / np.linalg.norm(spectrum1)\n",
    "    spectrum2_norm = spectrum2 / np.linalg.norm(spectrum2)\n",
    "    \n",
    "    # Reshape spectra into column vectors (required for cosine similarity calculation)\n",
    "    spectrum1_norm = spectrum1_norm.reshape(-1, 1)\n",
    "    spectrum2_norm = spectrum2_norm.reshape(-1, 1)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(spectrum1_norm.T, spectrum2_norm.T)[0, 0]   \n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a0657-55c3-4adf-98d2-aedbe5b15348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_pairs(items):\n",
    "    return list(combinations(items, 2))\n",
    "def at_least_three_above_threshold(numbers, threshold=0.6):\n",
    "    return sum(1 for num in numbers if num > threshold) >= 3\n",
    "\n",
    "def redshiftgood(redshift):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    cov_transitions=[]\n",
    "    for transition_check in species['HI']:\n",
    "        if  wave[0] <= species['HI'][transition_check][0]*(1.0+redshift) <= wave[-1]:\n",
    "            cov_transitions.append(transition_check)\n",
    "    use_species = myfuncpyNorm.speciesinterest(['HI'],transition_library,choose={'HI':cov_transitions})\n",
    "    \n",
    "    makeinpdict = getdictsep(wave,flux,err,use_species,redshift)\n",
    "\n",
    "    ups = unique_pairs(cov_transitions)\n",
    "    \n",
    "    cossim_values = OrderedDict()\n",
    "    for up in ups:\n",
    "        cossim_values[up] = cossim('HI_{}'.format(up[0]),'HI_{}'.format(up[1]),makeinpdict) \n",
    "    \n",
    "    firstquant, median, thirdquant = np.quantile(list(cossim_values.values()),[0.25,0.5,0.75])\n",
    "    minval, maxval = np.min(list(cossim_values.values())),np.max(list(cossim_values.values()))\n",
    "\n",
    "\n",
    "    if (maxval >= 0.8) and (at_least_three_above_threshold(list(cossim_values.values()))):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad057b-9a24-4ff7-b52a-cec1c3a8b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_good = []\n",
    "for num, val in enumerate(res_list):\n",
    "    redshift_good.append(redshiftgood(val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d954874-ad7e-4f32-804c-74323c217603",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_res = [res for res, good in zip(res_list, redshift_good) if good == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263a2a4-85ee-4e18-a31d-49acc30c3f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(selected_res,open('selected_res_J121930+494052.pkl','wb'),protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4025b4-a7e7-412a-871d-8b1383f162a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_res = pd.read_pickle('selected_res_J121930+494052.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
